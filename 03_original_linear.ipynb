{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db177d9",
   "metadata": {},
   "source": [
    "## Recalling the last time I studied this\n",
    "\n",
    "Let me explain if you didn't read the project proposal. Several years before taking this AI/ML course, I performed a study to explain why electricity demand varies by day. It's a very basic question that if one can't answer then one doesn't have any business explaining anything else that goes on in electricity markets. I inherited the study using Heating Degree Days and Cooling Degree Days, and reimplemented it with a few more predictors like day of week and holidays.\n",
    "\n",
    "I used Excel's multiple linear regression on just a few summarized raw features, and it worked pretty well. I thought it was hot stuff, but my boss at the time, with a Ph.D. in Econometrics, said \"don't show this to anybody before seeing me\". Unfortunate events intevened and I was unable to ever have her review it, so I still don't know what errors she saw, but here I'll try to recreate it here **making the same mistakes**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa2baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "target_df = pd.read_pickle(\"dataframes/target_df.pickle.gz\", compression=\"infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0857691",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['SUM_HDD', 'SUM_CDD'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-254eb86901cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtarget_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sum_spp_load'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'is_Thursday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'is_Saturday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'is_Sunday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'is_holiday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SUM_CDD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SUM_HDD'\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtarget_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['SUM_HDD', 'SUM_CDD'] not in index\""
     ]
    }
   ],
   "source": [
    "target_df = target_df[['sum_spp_load', 'is_Thursday', 'is_Saturday', 'is_Sunday', 'is_holiday', 'SUM_CDD', 'SUM_HDD' ]]\n",
    "target_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## separate independent and dependent variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b83dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referencing https://www.analyticsvidhya.com/blog/2021/05/multiple-linear-regression-using-python-and-scikit-learn/\n",
    "\n",
    "# separate the target, or dependent, attribute from the predicting attributes\n",
    "X = target_df.drop('sum_spp_load',axis=1)\n",
    "# separate the target attribute into Y for model training \n",
    "y = target_df['sum_spp_load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783517b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa23188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm # import statsmodels \n",
    "\n",
    "#X = df[\"RM\"] ## X usually means our input variables (or independent variables)\n",
    "#y = target[\"MEDV\"] ## Y usually means our output/dependent variable\n",
    "X = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n",
    "\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(y, X).fit() ## sm.OLS(output, input)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1091085",
   "metadata": {},
   "source": [
    "## I got better results by adding a sequence number as a predictor, because historically electric demand has grown over time.\n",
    "The sequence number can cause a slightly better fit on growth over time. However, there is nothing that suggests that growth is linear.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc644cee",
   "metadata": {},
   "source": [
    "## How can I show that the sequence number is showing demand growth over time but isn't simply tying together similar days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cb333",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = target_df.drop('sum_spp_load',axis=1)\n",
    "X = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n",
    "X['sequence_num'] = X.index\n",
    "\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(y, X).fit() ## sm.OLS(output, input)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5e12f",
   "metadata": {},
   "source": [
    "## TODO: elaborate on the warnings above. To the best of my memory, these numbers fairly well match my previous results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b858a48",
   "metadata": {},
   "source": [
    "## TODO:  plot modeled vs. actual. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92ef6f",
   "metadata": {},
   "source": [
    "## What if I used EVERYTHING in my target DF all at once?\n",
    "I know, curse of dimensionality, strong colinearity, etc.  Not advised. But what does the model do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8501af3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# what if I used EVERYTHING in my original DF? \n",
    "target_df = pd.read_pickle(\"dataframes/target_df.pickle.gz\", compression=\"infer\").dropna()\n",
    "y = target_df['sum_spp_load']\n",
    "X = target_df.drop(['sum_spp_load', 'opday'],axis=1)\n",
    "X = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n",
    "X['sequence_num'] = X.index\n",
    "\n",
    "model = sm.OLS(y, X).fit() ## sm.OLS(output, input)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182ac99",
   "metadata": {},
   "source": [
    "## Todo:  save predictions for all points; compare later to ML models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d669df5",
   "metadata": {},
   "source": [
    "## What if I normalize the predictors and target first? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89e69b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d53556fa70cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# small constant to prevent div/0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## let's add an intercept (beta_0) to our model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# normalize target variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sm' is not defined"
     ]
    }
   ],
   "source": [
    "# what if I used EVERYTHING in my original DF? \n",
    "target_df = pd.read_pickle(\"dataframes/target_df.pickle.gz\", compression=\"infer\").dropna()\n",
    "y = target_df['sum_spp_load']\n",
    "X = target_df.drop(['sum_spp_load', 'opday'],axis=1)\n",
    "X['sequence_num'] = X.index\n",
    "\n",
    "# normalize predictor variables\n",
    "X=(X-X.min())/(X.max()-X.min() + 0.0001)  # small constant to prevent div/0\n",
    "\n",
    "X = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n",
    "\n",
    "# normalize target variable\n",
    "y=(y-y.min())/(y.max()-y.min())\n",
    "\n",
    "model = sm.OLS(y, X).fit() ## sm.OLS(output, input)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893dd27b",
   "metadata": {},
   "source": [
    "## Exactly the same results! \n",
    "\n",
    "OLS must be robust to normalization problems.  I can however now see the relative impact of each predictor variable by its coefficient magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290185e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next steps:  break out scikit-learn, and see what we can do with dimensionality reduction and modern altorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b336338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
